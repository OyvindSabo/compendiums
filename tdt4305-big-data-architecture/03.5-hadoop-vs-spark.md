# Hadoop vs Spark
Spark is very fast (Up to 100 times faster than Hadoop MapReduce). It runs up to ten times faster on disk. Spark can also perform batch processing, however, it really excels at streaming workloads, interactive queries, and machine-based learning.

Spark is a cluster-computing framework, meaning that it competes more with Hadoop MapReduce than with the entire Hadoop ecosystem. Spark does not have its own distributed filesystem, but can use HDFS.

| Hadoop (MapReduce)                   | Spark                                 |
|--------------------------------------|---------------------------------------|
| Writes all temporary transformations                                            to disk, then reads them from disk                                              again before proceeding.             | uses Resilient Distributed Datasets                                             (RDDs) and can do multiple                                                      transformations, maintaining the data                                           in memory (but also has the ability to                                          write temporarily to disk if necessary)                                         , making it very suitable for realtime                                          data streams.                         |
| Batch processing                     | Realtime processing                   |
| Hard to use.                         | Easy to use interface, also has                                                 interactive mode.                     |
| Can run on cheap commodity hardware  | Can run on cheap commodity hardware,                                            but can be slightly more expensive                                              since it requires more ram, but can                                             also be cheaper isnce it requires                                               fewer distributed systems.            |
| Requires high speed disks to be efficient                                                                            | Requires much memory, but is not                                                depending on high speed disks         |
| Not so fast                          | So fast!                              |
| Fault tolerant by duplication.       | Fault tolerant because RDDS are                                                 resilient and lost data can be                                                  recomputed from the source.           |
